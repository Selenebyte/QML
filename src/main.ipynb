{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "# Pennylane\n",
    "import pennylane as qml\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "\n",
    "# HTML\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Model\n",
    "from models.non_noise_models.model import quantum_model\n",
    "from models.noise_models.noise_model import quantum_noise_model\n",
    "\n",
    "# Helper functions\n",
    "from util.training.training_objectives import target_function\n",
    "from util.json.json_file_from_data import save_model_data_to_json_file\n",
    "\n",
    "# Visualization Figures\n",
    "from visualization.visualization import visualize_curve_under_training\n",
    "from visualization.visualization import visualize_real_part_of_parameters_under_training\n",
    "from visualization.visualization import (\n",
    "    visualize_complex_part_of_parameters_under_training,\n",
    ")\n",
    "from visualization.visualization import visualize_prediction_and_target_curve\n",
    "from visualization.visualization import visualize_loss_under_training\n",
    "\n",
    "# Training\n",
    "from models.train import train\n",
    "\n",
    "# Average Correlation\n",
    "from metrics.average_correlations import get_average_correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Parameters\n",
    "degree = 3\n",
    "\n",
    "fourier_coeff0 = torch.as_tensor([0.2]).to(device)\n",
    "fourier_coeffs_positive = torch.as_tensor([0.1 + 0.1j] * degree).to(device) # Dataset 1\n",
    "# fourier_coeffs_positive = torch.as_tensor([0.1 + 0.1j] + [0.0 + 0.0j] * (degree - 2) + [0.1 + 0.1j]).to(device)  # Dataset 2\n",
    "# fourier_coeffs_positive = torch.as_tensor([0.0 + 0.0j] * (degree - 3) + [0.1 + 0.1j] * (3)).to(device) # Dataset High frequencies\n",
    "# fourier_coeffs_positive = torch.as_tensor([0.1 + 0.1j] * (3) + [0.0 + 0.0j] * (degree - 3)).to(device) # Dataset Low frequencies\n",
    "fourier_coeffs_negative = torch.conj(fourier_coeffs_positive).to(device)\n",
    "fourier_coeffs = torch.cat(\n",
    "    (fourier_coeff0, fourier_coeffs_positive, fourier_coeffs_negative), 0\n",
    ")\n",
    "\n",
    "layers = 3\n",
    "\n",
    "parameter_shape = {\"parameters_\": (layers + 1, 3)}\n",
    "\n",
    "# Noise model\n",
    "fcond1 = qml.noise.op_eq(qml.Rot)\n",
    "\n",
    "def noise1(op, **kwargs):\n",
    "    for wire in op.wires:\n",
    "        qml.AmplitudeDamping(kwargs[\"gamma_A\"], wire)\n",
    "        qml.PhaseDamping(kwargs[\"gamma_P\"], wire)\n",
    "\n",
    "metadata = {\"gamma_A\": 0.75, \"gamma_P\": 0.75}\n",
    "noise_model = qml.NoiseModel({fcond1: noise1}, **metadata)\n",
    "\n",
    "# Validation set\n",
    "torch.manual_seed(0)\n",
    "validation_x = torch.distributions.uniform.Uniform(-10, 10).sample([100]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "(\n",
    "    mean_losses,\n",
    "    mean_pearson_correlations,\n",
    "    mean_real_fourier_pearson_correlations,\n",
    "    mean_imag_fourier_pearson_correlations,\n",
    "    mean_distance_correlations,\n",
    "    mean_real_fourier_distance_correlations,\n",
    "    mean_imag_fourier_distance_correlations,\n",
    "    mean_mutual_info,\n",
    "    mean_real_fourier_mutual_info,\n",
    "    mean_complex_fourier_mutual_info,\n",
    "    mean_cross_correlations,\n",
    "    mean_real_fourier_cross_correlations,\n",
    "    mean_complex_fourier_cross_correlations,\n",
    ") = get_average_correlation(\n",
    "    50,\n",
    "    validation_x,\n",
    "    fourier_coeffs,\n",
    "    parameter_shape,\n",
    "    degree,\n",
    "    layers,\n",
    "    device,\n",
    "    noise_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = {\n",
    "    f\"{parameter_shape[\"parameters\"]}\": {\n",
    "        \"mean_losses\": mean_losses.cpu().detach().numpy().tolist(),\n",
    "        \"mean_pearson_correlations\": mean_pearson_correlations.numpy().tolist(),\n",
    "        \"mean_real_fourier_pearson_correlations\": mean_real_fourier_pearson_correlations.numpy().tolist(),\n",
    "        \"mean_imag_fourier_pearson_correlations\": mean_imag_fourier_pearson_correlations.numpy().tolist(),\n",
    "        \"mean_distance_correlations\": mean_distance_correlations.numpy().tolist(),\n",
    "        \"mean_real_fourier_distance_correlations\": mean_real_fourier_distance_correlations.numpy().tolist(),\n",
    "        \"mean_imag_fourier_distance_correlations\": mean_imag_fourier_distance_correlations.numpy().tolist(),\n",
    "        \"mean_mutual_info\": mean_mutual_info.numpy().tolist(),\n",
    "        \"mean_real_fourier_mutual_info\": mean_real_fourier_mutual_info.numpy().tolist(),\n",
    "        \"mean_complex_fourier_mutual_info\": mean_complex_fourier_mutual_info.numpy().tolist(),\n",
    "        \"mean_cross_correlations\": mean_cross_correlations.numpy().tolist(),\n",
    "        \"mean_real_fourier_cross_correlations\": mean_real_fourier_cross_correlations.numpy().tolist(),\n",
    "        \"mean_complex_fourier_cross_correlations\": mean_complex_fourier_cross_correlations.numpy().tolist(),\n",
    "    }\n",
    "}\n",
    "\n",
    "save_model_data_to_json_file(model_data, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed\n",
    "torch.manual_seed(0)\n",
    "x = torch.linspace(-10, 10, 100, requires_grad=False).to(device)\n",
    "\n",
    "dev = qml.device(\"default.qubit\", wires=1)\n",
    "# dev = qml.device(\"default.mixed\", wires=1)\n",
    "\n",
    "model = quantum_model(parameter_shape, dev)\n",
    "# model = quantum_noise_model(parameter_shape, dev, noise_model)\n",
    "\n",
    "target_y_no_noise = target_function(x, fourier_coeffs, device)\n",
    "scaling = torch.ceil(torch.max(target_y_no_noise)).to(torch.int)\n",
    "target_y_no_noise = target_y_no_noise / scaling\n",
    "target_y = target_y_no_noise\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "(\n",
    "    loss_list,\n",
    "    parameters_list,\n",
    "    parameters_grad_list,\n",
    "    fourier_coef_list,\n",
    "    fourier_coef_grad_list,\n",
    ") = train(\n",
    "    model,\n",
    "    x,\n",
    "    target_y,\n",
    "    optimizer,\n",
    "    loss_fn,\n",
    "    layers,\n",
    "    epochs,\n",
    "    dev,\n",
    "    device,\n",
    "    # noise_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani = visualize_curve_under_training(\n",
    "    x, target_y_no_noise, fourier_coef_list, device, reverse_conj_coef=True\n",
    ")\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani = visualize_real_part_of_parameters_under_training(\n",
    "    parameters_list, parameters_grad_list\n",
    ")\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani = visualize_complex_part_of_parameters_under_training(\n",
    "    fourier_coef_list, fourier_coef_grad_list\n",
    ")\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = visualize_prediction_and_target_curve(x, target_y_no_noise, model)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = visualize_loss_under_training(loss_list)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bachelor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
